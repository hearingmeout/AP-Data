{
  "id": "VR597082",
  "type": "mcq",
  "title": "Thinking It Through - coordination",
  "content": {
    "description": "(The following passage is excerpted from a philosophy textbook published in 2003.)\n\nIn countless movies, computers play a starring role. Some talk in synthesized voices; others write a stream of words on a screen. Some manage spaceships; others, the “brains” of robots, manage their own “bodies.” People converse with them, are understood by them, exchange information and greetings with them. Much of this is still science fiction. But real computers advise lawyers on relevant cases, doctors on diagnoses, engineers on the state of atomic reactors. Both the fantasy and the fact would have astonished our grandparents. Their grandparents might have thought that this could only be achieved by magic. Yet most of us are getting used to it, taking the silicon age for granted.\nStill, a suspicion remains. We human beings have always thought of ourselves as special. We all assume some contrast between the world of material things and the world of spiritual things. If the computer really is a “material mind,” then not only must we rethink this distinction, but we have broken it with our own creations. We should be careful to avoid such an important conclusion until we have really thought it through. However natural it seems to take it for granted that computers can think and act, then, we shouldn’t just assume it. In philosophy we often find that what we normally take for granted—the “commonsense” point of view—gets in the way of a proper understanding of the issues. So let’s see if the way I spoke about computers in the first paragraph is accurate.\nI said that they talk. But do they really talk in the sense that people do? It isn’t enough to say that they produce something that sounds like speech. Tape recorders do that, but they don’t talk. When people talk they mean something by what they say. To mean something, they need to be able to understand sentences. Now I also said that computers understand what we say to them. But do they really? The sounds of our speech are turned into electrical impulses. The impulses pass through the circuits of the machine. And that causes the speech synthesizer to produce sounds. It may be very clever to design a machine that does this, but what evidence do we have that the machine understands?\nWell, could a machine understand? There are two obvious responses to this question. The first response I’ll call mentalist, for the sake of a label. It’s the response you make if you think that understanding what people say involves having a mind. The mentalist says:\nComputers can’t really understand anything. To understand they would have to have conscious minds. But we made them from silicon chips and we programmed them. We didn’t give them conscious minds. So we know they don’t have them.\nAt the other extreme is the response I’ll call behaviorist. The behaviorist says:\nNaturally, everyone should agree that some computers don’t understand. But there’s no reason why a computer couldn’t be made that does understand. If a machine responds in the same ways to speech as a person who understands speech, then we have just as much reason to say that the machine understands as we have to say that the person does. A machine that behaves in every way as if it understands is indistinguishable from a machine that understands. If it behaved in the right way, that would show that it had a mind.\nIt is clear why I call this response “behaviorist.” For the behaviorist says that to understand is to behave as if you understand.\nWhat we have here is a situation that is quite familiar in philosophy. There are two opposing views—mentalist and behaviorist, in this case—each of which seems to have something in its favor, but neither of which looks completely right. Each of these views has a bit of common sense on its side. The mentalist relies on the common sense claim that machines can’t think. The behaviorist relies on the common sense claim that all we know about other people’s minds we know from what they do. It looks as though common sense here isn’t going to tell us if the mentalist or the behaviorist is right.",
    "question": "In paragraph 3, sentence 12 (“It may … machine understands”), the writer uses coordination to suggest that",
    "image": null,
    "choices": [
      {
        "label": "a computer’s capacity for complex tasks is not necessarily a sign of its intelligence",
        "image": null
      },
      {
        "label": "a computer will necessarily be less intelligent than are the humans who designed it",
        "image": null
      },
      {
        "label": "a computer may be more intelligent than its designers initially intended it to be",
        "image": null
      },
      {
        "label": "a computer’s intelligence cannot be adequately described by the terms applied to human intelligence",
        "image": null
      }
    ],
    "answer": "a computer’s capacity for complex tasks is not necessarily a sign of its intelligence"
  },
  "unit": {
    "code": "7",
    "text": "7"
  },
  "skill": {
    "code": "Skill 7.B",
    "text": "Skill 7.B: Explain how writers create, combine, and place independent and dependent clauses to show relationships between and among ideas."
  }
}